{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ada144-3454-4188-8626-6796169d6ca2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Kenan Stredic \n",
    "CS 4371 HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "458babd2-4199-4421-a160-0d9571ee11fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "233ada22-0ffe-4eaf-a291-6ded1b939b5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[48]: 512"
     ]
    }
   ],
   "source": [
    "# Load the text file\n",
    "text_rdd = sc.textFile(\"dbfs:/FileStore/shared_uploads/kstredic02@hotmail.com/input_hw1.txt\")\n",
    "\n",
    "# Data preprocessing: Split lines into words, convert to lowercase, and remove punctuation\n",
    "import re\n",
    "word_rdd = text_rdd.flatMap(lambda line: re.split(r'\\W+', line.lower()))\n",
    "\n",
    "# Word Count\n",
    "word_count = word_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Specific Word Counts\n",
    "specific_words = [\"america\", \"president\", \"washington\"]\n",
    "specific_word_counts = word_count.filter(lambda x: x[0] in specific_words)\n",
    "\n",
    "# Top 10 Words\n",
    "top_10_words = word_count.takeOrdered(10, key=lambda x: -x[1])\n",
    "\n",
    "# Save Question 1 results to one output text file\n",
    "combined_question1_results = word_count.union(specific_word_counts).union(sc.parallelize(top_10_words))\n",
    "combined_question1_results.coalesce(1).saveAsTextFile(\"/FileStore/shared_uploads/kstredic02@hotmail.com/question1_combined_results.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7988b3c9-3d97-4b96-9582-9ea07c359833",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8edb3ac7-3bfd-49b1-945a-89591bc04364",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the input files\n",
    "temperature_rdd = sc.textFile(\"dbfs:/FileStore/shared_uploads/kstredic02@hotmail.com/city_temperature.csv\")\n",
    "country_list_rdd = sc.textFile(\"dbfs:/FileStore/shared_uploads/kstredic02@hotmail.com/country_list.csv\")\n",
    "\n",
    "# Data preprocessing for temperature data\n",
    "temperature_data = temperature_rdd.map(lambda line: line.split(\",\"))\n",
    "temperature_data = temperature_data.filter(lambda row: row[0] != \"Region\")  # Remove header\n",
    "\n",
    "# Data preprocessing for country list data\n",
    "country_data = country_list_rdd.map(lambda line: line.split(\",\"))\n",
    "country_data = country_data.filter(lambda row: row[2] == \"country\")  # Filter by type\n",
    "\n",
    "# Sub-Question A - Average Temperature by Region\n",
    "region_avg_temp = temperature_data.map(lambda row: (row[0], (float(row[7]), 1)))\n",
    "region_avg_temp = region_avg_temp.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "region_avg_temp = region_avg_temp.map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    "\n",
    "# Sub-Question B - Average Temperature by Year (Asia Region)\n",
    "asia_avg_temp = temperature_data.filter(lambda row: row[0] == \"Asia\")\n",
    "asia_avg_temp = asia_avg_temp.map(lambda row: ((row[6], row[7]), float(row[7])))\n",
    "asia_avg_temp = asia_avg_temp.reduceByKey(lambda a, b: a + b)\n",
    "asia_avg_temp = asia_avg_temp.map(lambda x: (x[0][0], (x[0][1], x[1])))\n",
    "asia_avg_temp = asia_avg_temp.reduceByKey(lambda a, b: (a[0], a[1] + b[1]))\n",
    "asia_avg_temp = asia_avg_temp.map(lambda x: (x[0], x[1][1] / len(x[1][0])))\n",
    "\n",
    "# Sub-Question C - Average Temperature by City (Spain)\n",
    "spain_avg_temp = temperature_data.filter(lambda row: row[2] == \"Spain\")\n",
    "spain_avg_temp = spain_avg_temp.map(lambda row: (row[3], float(row[7])))\n",
    "spain_avg_temp = spain_avg_temp.reduceByKey(lambda a, b: a + b)\n",
    "spain_avg_temp = spain_avg_temp.map(lambda x: (x[0], x[1] / len(x[1])))\n",
    "                                    \n",
    "# Sub-Question D - Capital and Average Temperature\n",
    "capital_avg_temp = country_data.join(temperature_data.map(lambda row: (row[1], (float(row[7]), 1))))\n",
    "capital_avg_temp = capital_avg_temp.map(lambda x: (x[1][0], x[1][1]))\n",
    "capital_avg_temp = capital_avg_temp.reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
    "capital_avg_temp = capital_avg_temp.filter(lambda x: x[1][1] > 0)\n",
    "capital_avg_temp = capital_avg_temp.map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
    "\n",
    "# Save Question 2 results to another output text file\n",
    "combined_question2_results = region_avg_temp.union(asia_avg_temp).union(spain_avg_temp).union(capital_avg_temp)\n",
    "combined_question2_results.coalesce(1).saveAsTextFile(\"/FileStore/shared_uploads/kstredic02@hotmail.com/question2_combined_results.txt\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "CS 4371 HW3",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
